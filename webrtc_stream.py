"""
WebRTC ä½å»¶è¿Ÿè§†é¢‘æµæœåŠ¡å™¨
ä½¿ç”¨ aiortc å®ç° 100-300ms å»¶è¿Ÿçš„å®æ—¶è§†é¢‘æµ
"""
import sys
import json
import asyncio
import cv2
import time
from pathlib import Path
from typing import Optional

# Windows æ§åˆ¶å° UTF-8 ç¼–ç 
if sys.platform == "win32":
    try:
        sys.stdout.reconfigure(encoding='utf-8')
    except:
        pass

from aiohttp import web
from aiortc import RTCPeerConnection, RTCSessionDescription
from aiortc.contrib.media import MediaPlayer
from av import VideoFrame


class WebRTCStreamServer:
    """WebRTC è§†é¢‘æµæœåŠ¡å™¨"""

    def __init__(self, camera_index: int = 0, width: int = 640, height: int = 480):
        self.camera_index = camera_index
        self.width = width
        self.height = height
        self.pc = None
        self.cap = None

    async def camera_track_generator(self):
        """ç”Ÿæˆå™¨ï¼šä»æ‘„åƒå¤´è¯»å–å¸§"""
        print("[WebRTC] åˆå§‹åŒ–æ‘„åƒå¤´...")
        self.cap = cv2.VideoCapture(self.camera_index)

        if not self.cap.isOpened():
            print(f"[WebRTC] æ— æ³•æ‰“å¼€æ‘„åƒå¤´ (ç´¢å¼•: {self.camera_index})")
            return

        # è®¾ç½®æ‘„åƒå¤´å‚æ•°
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.width)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.height)
        self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # ä½å»¶è¿Ÿ

        actual_width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        actual_height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        print(f"[WebRTC] æ‘„åƒå¤´åˆå§‹åŒ–æˆåŠŸ: {actual_width}x{actual_height}")

        frame_time = 0
        frame_count = 0
        fps_target = 30
        frame_duration = 1.0 / fps_target

        try:
            while True:
                start_time = time.time()

                # è¯»å–å¸§
                ret, frame = self.cap.read()
                if not ret:
                    print("[WebRTC] è¯»å–å¸§å¤±è´¥ï¼Œå°è¯•é‡æ–°æ‰“å¼€æ‘„åƒå¤´...")
                    self.cap.release()
                    self.cap = cv2.VideoCapture(self.camera_index)
                    self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.width)
                    self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.height)
                    self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
                    continue

                # è½¬æ¢é¢œè‰²ç©ºé—´ BGR -> RGB
                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

                # åˆ›å»º VideoFrame
                video_frame = VideoFrame.from_ndarray(frame, format="rgb24")
                video_frame.pts = int(frame_time * 90000)  # 90kHz æ—¶é’Ÿ
                video_frame.time_base = "1/90000"

                yield video_frame

                frame_time += frame_duration
                frame_count += 1

                # æ¯30å¸§è¾“å‡ºä¸€æ¬¡
                if frame_count % 30 == 0:
                    elapsed = time.time() - start_time
                    print(f"[WebRTC] å·²å‘é€ {frame_count} å¸§")

                # æ§åˆ¶å¸§ç‡
                elapsed = time.time() - start_time
                sleep_time = frame_duration - elapsed
                if sleep_time > 0:
                    await asyncio.sleep(sleep_time)

        except Exception as e:
            print(f"[WebRTC] æ‘„åƒå¤´é”™è¯¯: {e}")
        finally:
            if self.cap:
                self.cap.release()
                print("[WebRTC] æ‘„åƒå¤´å·²å…³é—­")

    async def offer(self, request):
        """å¤„ç† WebRTC offer"""
        params = await request.json()
        offer = RTCSessionDescription(sdp=params["sdp"], type=params["type"])

        from aiortc import RTCPeerConnection
        self.pc = RTCPeerConnection()
        self.pc.addTrack(self.camera_track_generator())

        # è®¾ç½®è¿œç¨‹æè¿°
        await self.pc.setRemoteDescription(offer)

        # åˆ›å»º answer
        answer = await self.pc.createAnswer()
        await self.pc.setLocalDescription(answer)

        return web.Response(
            content_type="application/json",
            text=json.dumps({
                "sdp": self.pc.localDescription.sdp,
                "type": self.pc.localDescription.type
            })
        )

    async def index(self, request):
        """ä¸»é¡µ"""
        return web.Response(
            text=self.get_html_page(),
            content_type="text/html"
        )

    def get_html_page(self):
        """ç”Ÿæˆ HTML é¡µé¢"""
        return """
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WebRTC ä½å»¶è¿Ÿè§†é¢‘æµ</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
            background: #0f1419;
            color: #fff;
            padding: 20px;
            min-height: 100vh;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
        }
        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 30px;
            border-radius: 10px;
            margin-bottom: 20px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.3);
        }
        .header h1 {
            font-size: 28px;
            margin-bottom: 10px;
        }
        .stats {
            background: rgba(255,255,255,0.1);
            padding: 15px;
            border-radius: 8px;
            margin-top: 15px;
            font-family: monospace;
            font-size: 14px;
        }
        .video-container {
            background: #000;
            border-radius: 10px;
            overflow: hidden;
            box-shadow: 0 4px 20px rgba(0,0,0,0.5);
            margin-bottom: 20px;
        }
        #video {
            width: 100%;
            height: auto;
            display: block;
            background: #000;
        }
        .controls {
            display: flex;
            gap: 15px;
            flex-wrap: wrap;
            margin-bottom: 20px;
        }
        .btn {
            padding: 12px 30px;
            border: none;
            border-radius: 8px;
            font-size: 16px;
            cursor: pointer;
            transition: all 0.3s;
            font-weight: 600;
        }
        .btn-start {
            background: #4caf50;
            color: white;
        }
        .btn-start:hover { background: #45a049; }
        .btn-stop {
            background: #f44336;
            color: white;
        }
        .btn-stop:hover { background: #da190b; }
        .btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }
        .info-panel {
            background: #161b22;
            border: 1px solid #30363d;
            border-radius: 8px;
            padding: 20px;
            margin-bottom: 20px;
        }
        .info-panel h2 {
            color: #58a6ff;
            margin-bottom: 15px;
            font-size: 18px;
        }
        .info-item {
            display: flex;
            justify-content: space-between;
            padding: 10px 0;
            border-bottom: 1px solid #30363d;
        }
        .info-item:last-child { border-bottom: none; }
        .info-label { color: #8b949e; }
        .info-value { color: #c9d1d9; font-weight: 600; }
        .back-link {
            display: inline-block;
            color: #58a6ff;
            text-decoration: none;
            font-weight: 600;
        }
        .back-link:hover { text-decoration: underline; }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ¥ WebRTC ä½å»¶è¿Ÿè§†é¢‘æµ</h1>
            <p>è¶…ä½å»¶è¿Ÿå®æ—¶æ‘„åƒå¤´ç”»é¢ (é¢„æœŸå»¶è¿Ÿ: 100-300ms)</p>
            <div class="stats" id="stats">ç­‰å¾…è¿æ¥...</div>
        </div>

        <div class="video-container">
            <video id="video" autoplay playsinline muted></video>
        </div>

        <div class="controls">
            <button class="btn btn-start" id="btnStart" onclick="start()">å¯åŠ¨è§†é¢‘æµ</button>
            <button class="btn btn-stop" id="btnStop" onclick="stop()" disabled>åœæ­¢è§†é¢‘æµ</button>
        </div>

        <div class="info-panel">
            <h2>ğŸ“Š æŠ€æœ¯ä¿¡æ¯</h2>
            <div class="info-item">
                <span class="info-label">æŠ€æœ¯</span>
                <span class="info-value">WebRTC (aiortc)</span>
            </div>
            <div class="info-item">
                <span class="info-label">åˆ†è¾¨ç‡</span>
                <span class="info-value">640 x 480</span>
            </div>
            <div class="info-item">
                <span class="info-label">ç›®æ ‡å¸§ç‡</span>
                <span class="info-value">30 FPS</span>
            </div>
            <div class="info-item">
                <span class="info-label">é¢„æœŸå»¶è¿Ÿ</span>
                <span class="info-value">100-300ms</span>
            </div>
            <div class="info-item">
                <span class="info-label">ä¼˜åŠ¿</span>
                <span class="info-value">UDPä¼ è¾“ï¼Œç¡¬ä»¶åŠ é€Ÿï¼Œæ™ºèƒ½ç¼“å†²</span>
            </div>
        </div>

        <a href="/" class="back-link">â† è¿”å›ä¸»é¡µé¢</a>
    </div>

    <script>
        const video = document.getElementById('video');
        const btnStart = document.getElementById('btnStart');
        const btnStop = document.getElementById('btnStop');
        const stats = document.getElementById('stats');
        let pc = null;
        let startTime = null;
        let frameCount = 0;

        async function start() {
            try {
                stats.textContent = 'æ­£åœ¨è¿æ¥...';

                // åˆ›å»º RTCPeerConnection
                pc = new RTCPeerConnection({
                    iceServers: [{ urls: 'stun:stun.l.google.com:19302' }],
                    iceTransportPolicy: 'all'
                });

                // æ·»åŠ  transceiver
                pc.addTransceiver('video', { direction: 'recvonly' });

                // ç›‘å¬ candidates
                pc.onicecandidate = (event) => {
                    if (event.candidate === null) {
                        console.log('[WebRTC] ICE æ”¶é›†å®Œæˆ');
                    }
                };

                // ç›‘å¬è¿æ¥çŠ¶æ€
                pc.oniceconnectionstatechange = () => {
                    console.log('[WebRTC] ICE çŠ¶æ€:', pc.iceConnectionState);
                    if (pc.iceConnectionState === 'connected') {
                        startTime = Date.now();
                        updateStats();
                    }
                };

                pc.onconnectionstatechange = () => {
                    console.log('[WebRTC] è¿æ¥çŠ¶æ€:', pc.connectionState);
                    if (pc.connectionState === 'failed') {
                        stats.textContent = 'è¿æ¥å¤±è´¥';
                        stop();
                    }
                };

                // åˆ›å»º offer
                const offer = await pc.createOffer();
                await pc.setLocalDescription(offer);

                // å‘é€ offer åˆ°æœåŠ¡å™¨
                const response = await fetch('/offer', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        sdp: pc.localDescription.sdp,
                        type: pc.localDescription.type
                    })
                });

                if (!response.ok) {
                    throw new Error('æœåŠ¡å™¨è¿”å›é”™è¯¯: ' + response.status);
                }

                const answer = await response.json();
                await pc.setRemoteDescription(new RTCSessionDescription(answer));

                video.srcObject = await pc.recv();
                await video.play();

                stats.textContent = 'å·²è¿æ¥';
                btnStart.disabled = true;
                btnStop.disabled = false;

                // ç›‘æ§è§†é¢‘ç»Ÿè®¡
                video.addEventListener('play', () => {
                    startTime = Date.now();
                    updateStats();
                });

            } catch (error) {
                console.error('[WebRTC] é”™è¯¯:', error);
                stats.textContent = 'é”™è¯¯: ' + error.message;
                stop();
            }
        }

        async function stop() {
            try {
                if (pc) {
                    pc.close();
                    pc = null;
                }

                if (video.srcObject) {
                    video.srcObject.getTracks().forEach(track => track.stop());
                    video.srcObject = null;
                }

                stats.textContent = 'å·²åœæ­¢';
                btnStart.disabled = false;
                btnStop.disabled = true;

            } catch (error) {
                console.error('[WebRTC] åœæ­¢é”™è¯¯:', error);
            }
        }

        function updateStats() {
            if (!startTime || !video.srcObject) return;

            const elapsed = (Date.now() - startTime) / 1000;
            const stream = video.srcObject;
            const track = stream.getVideoTracks()[0];

            if (track && 'getStats' in track) {
                track.getStats().then(stats => {
                    stats.forEach(report => {
                        if (report.type === 'inbound-rtp' && 'framesReceived' in report) {
                            const fps = Math.round(report.framesReceived / elapsed);
                            const currentDelay = report.currentRoundTripTime || 0;
                            document.getElementById('stats').textContent =
                                `å·²è¿è¡Œ: ${elapsed.toFixed(1)}ç§’ | å¸§æ•°: ${report.framesReceived} | FPS: ${fps} | å»¶è¿Ÿ: ${currentDelay}ms`;
                        }
                    });
                });
            }

            requestAnimationFrame(updateStats);
        }
    </script>
</body>
</html>
"""

    async def on_shutdown(self, app):
        """å…³é—­æ—¶æ¸…ç†èµ„æº"""
        print("[WebRTC] æ­£åœ¨å…³é—­æœåŠ¡å™¨...")
        if self.cap:
            self.cap.release()


async def main():
    """ä¸»å‡½æ•°"""
    port = 8081
    camera_index = 0

    print("=" * 60)
    print("WebRTC ä½å»¶è¿Ÿè§†é¢‘æµæœåŠ¡å™¨")
    print("=" * 60)
    print(f"è®¿é—®åœ°å€: http://localhost:{port}")
    print(f"æ‘„åƒå¤´ç´¢å¼•: {camera_index}")
    print("=" * 60)

    server = WebRTCStreamServer(camera_index=camera_index)
    app = web.Application()
    app.router.add_get('/', server.index)
    app.router.add_post('/offer', server.offer)
    app.on_shutdown.append(server.on_shutdown)

    runner = web.AppRunner(app)
    await runner.setup()
    site = web.TCPSite(runner, '0.0.0.0', port)

    print(f"[WebRTC] æœåŠ¡å™¨å·²å¯åŠ¨: http://0.0.0.0:{port}")

    try:
        await site.start()
        print(f"[WebRTC] æœåŠ¡å™¨è¿è¡Œä¸­ï¼ŒæŒ‰ Ctrl+C åœæ­¢")
        # ä¿æŒè¿è¡Œ
        await asyncio.Future()
    except KeyboardInterrupt:
        print("\n[WebRTC] æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨å…³é—­...")
    finally:
        await runner.cleanup()


if __name__ == '__main__':
    try:
        # Windows ä¸‹ä½¿ç”¨ ProactorEventLoop
        if sys.platform == 'win32':
            asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n[WebRTC] æœåŠ¡å™¨å·²åœæ­¢")

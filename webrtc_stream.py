"""
WebRTC ä½å»¶è¿Ÿè§†é¢‘æµæœåŠ¡å™¨
ä½¿ç”¨ aiortc å®ç° 100-300ms å»¶è¿Ÿçš„å®æ—¶è§†é¢‘æµ
"""
import sys
import json
import asyncio
import cv2
import time
from pathlib import Path
from typing import Optional

# Windows æ§åˆ¶å° UTF-8 ç¼–ç 
if sys.platform == "win32":
    try:
        sys.stdout.reconfigure(encoding='utf-8')
    except:
        pass

from aiohttp import web
from aiortc import RTCPeerConnection, RTCSessionDescription, MediaStreamTrack
from aiortc.contrib.media import MediaPlayer
from av import VideoFrame
import tempfile
import os

# å…¨å±€å˜é‡ä¿æŒ track çš„å¼ºå¼•ç”¨ï¼Œé˜²æ­¢è¢« GC å›æ”¶
_global_tracks = []


# å¤‡ç”¨æ–¹æ¡ˆï¼šä¿æŒä½¿ç”¨è‡ªå®šä¹‰ Trackï¼Œä½†æ”¹è¿›å¼•ç”¨ç®¡ç†
class CameraStreamTrack(MediaStreamTrack):
    """è‡ªå®šä¹‰æ‘„åƒå¤´è§†é¢‘æµ Track"""

    kind = "video"

    # ç±»çº§åˆ«çš„æ‘„åƒå¤´å®ä¾‹ï¼Œæ‰€æœ‰ track å…±äº«
    _shared_cap = None
    _cap_lock = asyncio.Lock()

    def __init__(self, camera_index: int = 0, width: int = 640, height: int = 480):
        super().__init__()
        self.camera_index = camera_index
        self.width = width
        self.height = height
        self.pts = 0  # æ—¶é—´æˆ³
        # æ³¨æ„ï¼šä¸åœ¨ __init__ ä¸­æ‰“å¼€æ‘„åƒå¤´

    @classmethod
    async def ensure_camera(cls, camera_index: int, width: int, height: int):
        """ç¡®ä¿æ‘„åƒå¤´å·²æ‰“å¼€ï¼ˆç±»æ–¹æ³•ï¼‰"""
        async with cls._cap_lock:
            if cls._shared_cap is None or not cls._shared_cap.isOpened():
                print("[WebRTC] åˆå§‹åŒ–å…±äº«æ‘„åƒå¤´...")
                cls._shared_cap = cv2.VideoCapture(camera_index)

                if not cls._shared_cap.isOpened():
                    print(f"[WebRTC] æ— æ³•æ‰“å¼€æ‘„åƒå¤´ (ç´¢å¼•: {camera_index})")
                    return False

                # è®¾ç½®æ‘„åƒå¤´å‚æ•°
                cls._shared_cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)
                cls._shared_cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
                cls._shared_cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # ä½å»¶è¿Ÿ

                actual_width = int(cls._shared_cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                actual_height = int(cls._shared_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                print(f"[WebRTC] æ‘„åƒå¤´åˆå§‹åŒ–æˆåŠŸ: {actual_width}x{actual_height}")
        return True

    async def recv(self):
        """æ¥æ”¶ä¸‹ä¸€å¸§"""
        try:
            if self.pts == 0:
                print("[WebRTC] ========== recv() é¦–æ¬¡è¢«è°ƒç”¨ ==========")

            # ç¡®ä¿æ‘„åƒå¤´å·²æ‰“å¼€
            await self.ensure_camera(self.camera_index, self.width, self.height)

            if self._shared_cap is None or not self._shared_cap.isOpened():
                raise RuntimeError("æ‘„åƒå¤´æœªåˆå§‹åŒ–")

            # è¯»å–å¸§
            ret, frame = self._shared_cap.read()
            if not ret:
                print("[WebRTC] è¯»å–å¸§å¤±è´¥")
                raise RuntimeError("æ— æ³•è¯»å–æ‘„åƒå¤´å¸§")

            # è½¬æ¢é¢œè‰²ç©ºé—´ BGR -> RGB
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

            # åˆ›å»º VideoFrame
            video_frame = VideoFrame.from_ndarray(frame, format="rgb24")
            video_frame.pts = self.pts
            video_frame.time_base = "1/90000"  # 90kHz æ—¶é’Ÿ

            self.pts += 3000  # 33.33ms @ 90kHz (çº¦30fps)

            # æ¯30å¸§è¾“å‡ºä¸€æ¬¡æ—¥å¿—
            if self.pts % 90000 == 0:  # æ¯ç§’ä¸€æ¬¡
                print(f"[WebRTC] å‘é€å¸§: {video_frame.pts}, pts={video_frame.pts}")

            if self.pts == 3000:  # ç¬¬äºŒå¸§
                print("[WebRTC] ========== recv() æ­£å¸¸å·¥ä½œ ==========")

            return video_frame
        except Exception as e:
            print(f"[WebRTC] recv() å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            raise

    def stop(self):
        """stop() æ–¹æ³•ä¸å†å…³é—­æ‘„åƒå¤´ï¼Œå› ä¸ºå®ƒæ˜¯å…±äº«çš„"""
        print("[WebRTC] stop() è¢«è°ƒç”¨ï¼Œä½†ä¸å…³é—­å…±äº«æ‘„åƒå¤´")
        pass

    @classmethod
    def close_camera(cls):
        """å…³é—­å…±äº«æ‘„åƒå¤´ï¼ˆç±»æ–¹æ³•ï¼‰"""
        if cls._shared_cap:
            cls._shared_cap.release()
            cls._shared_cap = None
            print("[WebRTC] å…±äº«æ‘„åƒå¤´å·²å…³é—­")


class WebRTCStreamServer:
    """WebRTC è§†é¢‘æµæœåŠ¡å™¨"""

    def __init__(self, camera_index: int = 0, width: int = 640, height: int = 480):
        self.camera_index = camera_index
        self.width = width
        self.height = height
        self.pc = None
        self.camera_track = None  # å°†åœ¨ offer ä¸­åˆ›å»º

    async def offer(self, request):
        """å¤„ç† WebRTC offer"""
        print("[WebRTC] ========== offer() è¢«è°ƒç”¨ ==========")
        params = await request.json()
        print(f"[WebRTC] æ”¶åˆ° offer type: {params['type']}")
        print(f"[WebRTC] offer SDP é•¿åº¦: {len(params['sdp'])} å­—ç¬¦")
        # æ£€æŸ¥ SDP ä¸­æ˜¯å¦æœ‰è§†é¢‘æè¿°
        if 'm=video' in params['sdp']:
            print("[WebRTC] âœ“ SDP åŒ…å«è§†é¢‘æè¿°")
        else:
            print("[WebRTC] âœ— SDP ä¸åŒ…å«è§†é¢‘æè¿°ï¼")

        offer = RTCSessionDescription(sdp=params["sdp"], type=params["type"])

        from aiortc import RTCPeerConnection
        self.pc = RTCPeerConnection()

        # åˆ›å»ºæ‘„åƒå¤´ track
        if self.camera_track is None:
            print("[WebRTC] åˆ›å»ºæ–°çš„ CameraStreamTrack")
            self.camera_track = CameraStreamTrack(
                camera_index=self.camera_index,
                width=self.width,
                height=self.height
            )
            # æ·»åŠ åˆ°å…¨å±€åˆ—è¡¨ä»¥ä¿æŒå¼ºå¼•ç”¨ï¼ˆé˜²æ­¢ GCï¼‰
            _global_tracks.append(self.camera_track)
        else:
            print("[WebRTC] å¤ç”¨å·²æœ‰çš„ CameraStreamTrack")

        # æ·»åŠ  track åˆ°è¿æ¥
        print("[WebRTC] æ·»åŠ  track åˆ° RTCPeerConnection")
        self.pc.addTrack(self.camera_track)
        # ä¹Ÿå°† pc æ·»åŠ åˆ°å…¨å±€åˆ—è¡¨
        _global_tracks.append(self.pc)

        # è®¾ç½®è¿œç¨‹æè¿°
        print("[WebRTC] è®¾ç½®è¿œç¨‹æè¿°")
        await self.pc.setRemoteDescription(offer)

        # åˆ›å»º answer
        print("[WebRTC] åˆ›å»º answer")
        answer = await self.pc.createAnswer()
        await self.pc.setLocalDescription(answer)

        print("[WebRTC] ========== offer() å®Œæˆ ==========")

        # ç›‘å¬è¿æ¥çŠ¶æ€
        @self.pc.on("connectionstatechange")
        async def on_connectionstatechange():
            print(f"[WebRTC] è¿æ¥çŠ¶æ€å˜æ›´: {self.pc.connectionState}")
            if self.pc.connectionState == "connected":
                print("[WebRTC] è¿æ¥å·²å»ºç«‹ï¼Œåº”è¯¥å¼€å§‹ä¼ è¾“æ•°æ®")

        return web.Response(
            content_type="application/json",
            text=json.dumps({
                "sdp": self.pc.localDescription.sdp,
                "type": self.pc.localDescription.type
            })
        )

    async def index(self, request):
        """ä¸»é¡µ"""
        return web.Response(
            text=self.get_html_page(),
            content_type="text/html"
        )

    def get_html_page(self):
        """ç”Ÿæˆ HTML é¡µé¢"""
        return """
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WebRTC ä½å»¶è¿Ÿè§†é¢‘æµ</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
            background: #0f1419;
            color: #fff;
            padding: 20px;
            min-height: 100vh;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
        }
        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 30px;
            border-radius: 10px;
            margin-bottom: 20px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.3);
        }
        .header h1 {
            font-size: 28px;
            margin-bottom: 10px;
        }
        .stats {
            background: rgba(255,255,255,0.1);
            padding: 15px;
            border-radius: 8px;
            margin-top: 15px;
            font-family: monospace;
            font-size: 14px;
        }
        .video-container {
            background: #000;
            border-radius: 10px;
            overflow: hidden;
            box-shadow: 0 4px 20px rgba(0,0,0,0.5);
            margin-bottom: 20px;
        }
        #video {
            width: 100%;
            height: auto;
            display: block;
            background: #000;
        }
        .controls {
            display: flex;
            gap: 15px;
            flex-wrap: wrap;
            margin-bottom: 20px;
        }
        .btn {
            padding: 12px 30px;
            border: none;
            border-radius: 8px;
            font-size: 16px;
            cursor: pointer;
            transition: all 0.3s;
            font-weight: 600;
        }
        .btn-start {
            background: #4caf50;
            color: white;
        }
        .btn-start:hover { background: #45a049; }
        .btn-stop {
            background: #f44336;
            color: white;
        }
        .btn-stop:hover { background: #da190b; }
        .btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }
        .info-panel {
            background: #161b22;
            border: 1px solid #30363d;
            border-radius: 8px;
            padding: 20px;
            margin-bottom: 20px;
        }
        .info-panel h2 {
            color: #58a6ff;
            margin-bottom: 15px;
            font-size: 18px;
        }
        .info-item {
            display: flex;
            justify-content: space-between;
            padding: 10px 0;
            border-bottom: 1px solid #30363d;
        }
        .info-item:last-child { border-bottom: none; }
        .info-label { color: #8b949e; }
        .info-value { color: #c9d1d9; font-weight: 600; }
        .back-link {
            display: inline-block;
            color: #58a6ff;
            text-decoration: none;
            font-weight: 600;
        }
        .back-link:hover { text-decoration: underline; }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ¥ WebRTC ä½å»¶è¿Ÿè§†é¢‘æµ</h1>
            <p>è¶…ä½å»¶è¿Ÿå®æ—¶æ‘„åƒå¤´ç”»é¢ (é¢„æœŸå»¶è¿Ÿ: 100-300ms)</p>
            <div class="stats" id="stats">ç­‰å¾…è¿æ¥...</div>
        </div>

        <div class="video-container">
            <video id="video" autoplay playsinline muted></video>
        </div>

        <div class="controls">
            <button class="btn btn-start" id="btnStart" onclick="start()">å¯åŠ¨è§†é¢‘æµ</button>
            <button class="btn btn-stop" id="btnStop" onclick="stop()" disabled>åœæ­¢è§†é¢‘æµ</button>
        </div>

        <div class="info-panel">
            <h2>ğŸ“Š æŠ€æœ¯ä¿¡æ¯</h2>
            <div class="info-item">
                <span class="info-label">æŠ€æœ¯</span>
                <span class="info-value">WebRTC (aiortc)</span>
            </div>
            <div class="info-item">
                <span class="info-label">åˆ†è¾¨ç‡</span>
                <span class="info-value">640 x 480</span>
            </div>
            <div class="info-item">
                <span class="info-label">ç›®æ ‡å¸§ç‡</span>
                <span class="info-value">30 FPS</span>
            </div>
            <div class="info-item">
                <span class="info-label">é¢„æœŸå»¶è¿Ÿ</span>
                <span class="info-value">100-300ms</span>
            </div>
            <div class="info-item">
                <span class="info-label">ä¼˜åŠ¿</span>
                <span class="info-value">UDPä¼ è¾“ï¼Œç¡¬ä»¶åŠ é€Ÿï¼Œæ™ºèƒ½ç¼“å†²</span>
            </div>
        </div>

        <a href="/" class="back-link">â† è¿”å›ä¸»é¡µé¢</a>
    </div>

    <script>
        const video = document.getElementById('video');
        const btnStart = document.getElementById('btnStart');
        const btnStop = document.getElementById('btnStop');
        const stats = document.getElementById('stats');
        let pc = null;
        let startTime = null;
        let frameCount = 0;

        async function start() {
            try {
                stats.textContent = 'æ­£åœ¨è¿æ¥...';

                // åˆ›å»º RTCPeerConnection
                pc = new RTCPeerConnection({
                    iceServers: [{ urls: 'stun:stun.l.google.com:19302' }],
                    iceTransportPolicy: 'all'
                });

                // æ·»åŠ  transceiver
                pc.addTransceiver('video', { direction: 'recvonly' });

                // ç›‘å¬ incoming track
                pc.ontrack = (event) => {
                    console.log('[WebRTC] æ”¶åˆ°è§†é¢‘æµ');
                    console.log('[WebRTC] track kind:', event.track.kind);
                    console.log('[WebRTC] streams:', event.streams.length);
                    console.log('[WebRTC] stream tracks:', event.streams[0]?.getTracks().length);

                    if (event.track.kind === 'video') {
                        video.srcObject = event.streams[0];

                        // æ£€æŸ¥è§†é¢‘å…ƒç´ 
                        video.addEventListener('loadedmetadata', () => {
                            console.log('[WebRTC] è§†é¢‘å°ºå¯¸:', video.videoWidth, 'x', video.videoHeight);
                        });

                        video.addEventListener('playing', () => {
                            console.log('[WebRTC] è§†é¢‘å¼€å§‹æ’­æ”¾');
                        });

                        video.play()
                            .then(() => {
                                console.log('[WebRTC] è§†é¢‘æ’­æ”¾æˆåŠŸ');
                                startTime = Date.now();
                                updateStats();
                            })
                            .catch(err => {
                                console.error('[WebRTC] è§†é¢‘æ’­æ”¾å¤±è´¥:', err);
                            });
                    }
                };

                // ç›‘å¬ candidates
                pc.onicecandidate = (event) => {
                    if (event.candidate === null) {
                        console.log('[WebRTC] ICE æ”¶é›†å®Œæˆ');
                    }
                };

                // ç›‘å¬è¿æ¥çŠ¶æ€
                pc.oniceconnectionstatechange = () => {
                    console.log('[WebRTC] ICE çŠ¶æ€:', pc.iceConnectionState);
                    if (pc.iceConnectionState === 'connected') {
                        stats.textContent = 'å·²è¿æ¥';
                        btnStart.disabled = true;
                        btnStop.disabled = false;
                    } else if (pc.iceConnectionState === 'failed') {
                        stats.textContent = 'è¿æ¥å¤±è´¥';
                        stop();
                    }
                };

                pc.onconnectionstatechange = () => {
                    console.log('[WebRTC] è¿æ¥çŠ¶æ€:', pc.connectionState);
                    if (pc.connectionState === 'failed') {
                        stats.textContent = 'è¿æ¥å¤±è´¥';
                        stop();
                    }
                };

                // åˆ›å»º offer
                const offer = await pc.createOffer();
                await pc.setLocalDescription(offer);

                // å‘é€ offer åˆ°æœåŠ¡å™¨
                const response = await fetch('/offer', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        sdp: pc.localDescription.sdp,
                        type: pc.localDescription.type
                    })
                });

                if (!response.ok) {
                    throw new Error('æœåŠ¡å™¨è¿”å›é”™è¯¯: ' + response.status);
                }

                const answer = await response.json();
                await pc.setRemoteDescription(new RTCSessionDescription(answer));

                stats.textContent = 'ç­‰å¾…è§†é¢‘æµ...';

            } catch (error) {
                console.error('[WebRTC] é”™è¯¯:', error);
                stats.textContent = 'é”™è¯¯: ' + error.message;
                stop();
            }
        }

        async function stop() {
            try {
                if (pc) {
                    pc.close();
                    pc = null;
                }

                if (video.srcObject) {
                    video.srcObject.getTracks().forEach(track => track.stop());
                    video.srcObject = null;
                }

                stats.textContent = 'å·²åœæ­¢';
                btnStart.disabled = false;
                btnStop.disabled = true;

            } catch (error) {
                console.error('[WebRTC] åœæ­¢é”™è¯¯:', error);
            }
        }

        function updateStats() {
            if (!startTime || !video.srcObject) return;

            const elapsed = (Date.now() - startTime) / 1000;
            const stream = video.srcObject;
            const track = stream.getVideoTracks()[0];

            if (track && 'getStats' in track) {
                track.getStats().then(stats => {
                    stats.forEach(report => {
                        if (report.type === 'inbound-rtp' && 'framesReceived' in report) {
                            const fps = Math.round(report.framesReceived / elapsed);
                            const currentDelay = report.currentRoundTripTime || 0;
                            document.getElementById('stats').textContent =
                                `å·²è¿è¡Œ: ${elapsed.toFixed(1)}ç§’ | å¸§æ•°: ${report.framesReceived} | FPS: ${fps} | å»¶è¿Ÿ: ${currentDelay}ms`;
                        }
                    });
                });
            }

            requestAnimationFrame(updateStats);
        }
    </script>
</body>
</html>
"""

    async def on_shutdown(self, app):
        """å…³é—­æ—¶æ¸…ç†èµ„æº"""
        print("[WebRTC] æ­£åœ¨å…³é—­æœåŠ¡å™¨...")
        # å…³é—­å…±äº«æ‘„åƒå¤´
        CameraStreamTrack.close_camera()

        # æ¸…ç†å…¨å±€å¼•ç”¨
        global _global_tracks
        for item in _global_tracks:
            if hasattr(item, 'close'):
                await item.close()
        _global_tracks.clear()

        if self.pc:
            await self.pc.close()


async def main():
    """ä¸»å‡½æ•°"""
    port = 8081
    camera_index = 0

    print("=" * 60)
    print("WebRTC ä½å»¶è¿Ÿè§†é¢‘æµæœåŠ¡å™¨")
    print("=" * 60)
    print(f"è®¿é—®åœ°å€: http://localhost:{port}")
    print(f"æ‘„åƒå¤´ç´¢å¼•: {camera_index}")
    print("=" * 60)

    server = WebRTCStreamServer(camera_index=camera_index)
    app = web.Application()
    app.router.add_get('/', server.index)
    app.router.add_post('/offer', server.offer)
    app.on_shutdown.append(server.on_shutdown)

    runner = web.AppRunner(app)
    await runner.setup()
    site = web.TCPSite(runner, '0.0.0.0', port)

    print(f"[WebRTC] æœåŠ¡å™¨å·²å¯åŠ¨: http://0.0.0.0:{port}")

    try:
        await site.start()
        print(f"[WebRTC] æœåŠ¡å™¨è¿è¡Œä¸­ï¼ŒæŒ‰ Ctrl+C åœæ­¢")
        # ä¿æŒè¿è¡Œ
        await asyncio.Future()
    except KeyboardInterrupt:
        print("\n[WebRTC] æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨å…³é—­...")
    finally:
        await runner.cleanup()


if __name__ == '__main__':
    try:
        # Windows ä¸‹ä½¿ç”¨ ProactorEventLoop
        if sys.platform == 'win32':
            asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n[WebRTC] æœåŠ¡å™¨å·²åœæ­¢")
